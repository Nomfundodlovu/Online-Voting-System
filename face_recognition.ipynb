{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/The-DigitalAcademy/Online-Voting-System/blob/main/face_recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P9080LzpbLpg",
        "outputId": "629ce094-a247-4155-9deb-d4866fc8e78e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.13.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.23.5)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.8.0.76)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.1.21 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.5.26)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.57.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: keras<2.14,>=2.13.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.13.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.6)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: tensorboard<2.14,>=2.13 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.13.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.13.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.5.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.33.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.41.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (3.4.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (0.7.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.3.7)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (5.3.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow numpy opencv-python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l9gxWO1cn89a",
        "outputId": "38971c63-29d6-478d-ca40-2526256ada47"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mtcnn\n",
            "  Downloading mtcnn-0.1.1-py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: keras>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from mtcnn) (2.13.1)\n",
            "Requirement already satisfied: opencv-python>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from mtcnn) (4.8.0.76)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python>=4.1.0->mtcnn) (1.23.5)\n",
            "Installing collected packages: mtcnn\n",
            "Successfully installed mtcnn-0.1.1\n"
          ]
        }
      ],
      "source": [
        "!pip install mtcnn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qndomzftoUYp",
        "outputId": "e5738945-8328-4401-b72b-936850d76e0f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras-vggface\n",
            "  Downloading keras_vggface-0.6-py3-none-any.whl (8.3 kB)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.10/dist-packages (from keras-vggface) (1.23.5)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.10/dist-packages (from keras-vggface) (1.11.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras-vggface) (3.9.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from keras-vggface) (9.4.0)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (from keras-vggface) (2.13.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from keras-vggface) (1.16.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from keras-vggface) (6.0.1)\n",
            "Installing collected packages: keras-vggface\n",
            "Successfully installed keras-vggface-0.6\n"
          ]
        }
      ],
      "source": [
        "!pip install keras-vggface\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VuouihchAz3b"
      },
      "outputs": [],
      "source": [
        "!pip install typing-extensions>=4.7.1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pe6BADsDCaRx",
        "outputId": "b10fda9d-ffff-4d1a-9c38-e22087fd7ca5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.13.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.1.21 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.5.26)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.57.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: keras<2.14,>=2.13.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.13.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.6)\n",
            "Requirement already satisfied: numpy<=1.24.3,>=1.22 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.23.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: tensorboard<2.14,>=2.13 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.13.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.13.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.5.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.33.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.41.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (3.4.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (0.7.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.3.7)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (5.3.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "#!pip uninstall tensorflow\n",
        "!pip install tensorflow\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FFWARUJDo8HG",
        "outputId": "002c1af5-2712-45be-e5a9-0780677a2b75"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (2.13.1)\n",
            "Collecting keras\n",
            "  Downloading keras-2.14.0-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: keras\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.13.1\n",
            "    Uninstalling keras-2.13.1:\n",
            "      Successfully uninstalled keras-2.13.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.13.0 requires keras<2.14,>=2.13.1, but you have keras 2.14.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed keras-2.14.0\n"
          ]
        }
      ],
      "source": [
        "# !pip install --upgrade tensorflow\n",
        "!pip install --upgrade keras\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rgzfOje3eHRP"
      },
      "outputs": [],
      "source": [
        "train_path=\"/content/drive/MyDrive/voting_final_project/images/archive/Training/Training\"\n",
        "test_path=\"/content/drive/MyDrive/voting_final_project/images/archive/Testing/Testing\"\n",
        "#validation_path=\"/content/drive/MyDrive/voting_final_project/images/validation\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T30WmG9ldGMp"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, ZeroPadding2D, MaxPooling2D, \\\n",
        "                                    Dropout, Flatten, Activation\n",
        "\n",
        "\n",
        "def get_model():\n",
        "    model = Sequential()\n",
        "    model.add(ZeroPadding2D((1,1),input_shape=(32,32, 3)))\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "    model.add(ZeroPadding2D((1,1)))\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
        "\n",
        "    model.add(ZeroPadding2D((1,1)))\n",
        "    model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "    model.add(ZeroPadding2D((1,1)))\n",
        "    model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
        "\n",
        "    model.add(ZeroPadding2D((1,1)))\n",
        "    model.add(Conv2D(256, (3, 3), activation='relu'))\n",
        "    model.add(ZeroPadding2D((1,1)))\n",
        "    model.add(Conv2D(256, (3, 3), activation='relu'))\n",
        "    model.add(ZeroPadding2D((1,1)))\n",
        "    model.add(Conv2D(256, (3, 3), activation='relu'))\n",
        "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
        "\n",
        "    model.add(ZeroPadding2D((1,1)))\n",
        "    model.add(Conv2D(512, (3, 3), activation='relu'))\n",
        "    model.add(ZeroPadding2D((1,1)))\n",
        "    model.add(Conv2D(512, (3, 3), activation='relu'))\n",
        "    model.add(ZeroPadding2D((1,1)))\n",
        "    model.add(Conv2D(512, (3, 3), activation='relu'))\n",
        "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
        "\n",
        "    model.add(ZeroPadding2D((1,1)))\n",
        "    model.add(Conv2D(4096, (3, 3), activation='relu'))\n",
        "    model.add(ZeroPadding2D((1,1)))\n",
        "    model.add(Conv2D(4096, (3, 3), activation='relu'))\n",
        "    model.add(ZeroPadding2D((1,1)))\n",
        "    model.add(Conv2D(4096, (3, 3), activation='relu'))\n",
        "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
        "\n",
        "    model.add(Conv2D(4096, (7, 7), activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Conv2D(4096, (1, 1), activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Conv2D(2622, (1, 1)))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(6, activation='softmax'))\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dense"
      ],
      "metadata": {
        "id": "r-tuMQF8D82u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model():\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu',input_shape=(32,32, 3)))\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(6, activation='softmax'))\n",
        "    return model\n",
        "##\n",
        "my_model = create_model()\n",
        "my_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vpVuk_pGFMOb",
        "outputId": "5779897b-7e32-4ea3-849c-2654720b5dae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.engine.sequential.Sequential at 0x794a881ef250>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer=tf.keras.optimizers.Adam(learning_rate=0.001,\n",
        "                                   beta_1=0.9,\n",
        "                                   beta_2=0.999,\n",
        "                                   epsilon=1e-07)\n",
        "accuracy=tf.keras.metrics.Accuracy(name='accuracy', dtype=None)"
      ],
      "metadata": {
        "id": "rY9Zr8X4ox10"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import tensorflow as tf\n",
        "# from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "# from tensorflow.keras.optimizers import Adam\n",
        "# from tensorflow.keras.losses import categorical_crossentropy\n",
        "# from tensorflow.keras.metrics import Accuracy\n",
        "# from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# # Set the path to your dataset\n",
        "# train_path = '/content/drive/MyDrive/voting_final_project/images/archive/Training/Training'\n",
        "# test_path = '/content/drive/MyDrive/voting_final_project/images/archive/Testing/Testing'\n",
        "# num_classes = 6\n",
        "\n",
        "# # Data Preprocessing\n",
        "\n",
        "\n",
        "# train_datagen = ImageDataGenerator(\n",
        "#     rescale=1.0 / 255,\n",
        "#     rotation_range=20,\n",
        "#     width_shift_range=0.2,\n",
        "#     height_shift_range=0.2,\n",
        "#     shear_range=0.2,\n",
        "#     zoom_range=0.2,\n",
        "#     horizontal_flip=True,\n",
        "#     validation_split=0.2,\n",
        "# )\n",
        "\n",
        "# test_datagen = ImageDataGenerator(rescale=1.0 / 255)\n",
        "\n",
        "# # Use the 'flow_from_directory' method to load training and validation data.\n",
        "# train_generator = train_datagen.flow_from_directory(\n",
        "#     train_path,\n",
        "#     target_size=(32,32),\n",
        "#     batch_size=42,\n",
        "#     class_mode='categorical',\n",
        "#     subset='training',\n",
        "# )\n",
        "\n",
        "# validation_generator = train_datagen.flow_from_directory(\n",
        "#     train_path,\n",
        "#     target_size=(32 ,32),\n",
        "#     batch_size=32,\n",
        "#     class_mode='categorical',\n",
        "#     subset='validation',\n",
        "# )\n",
        "\n",
        "# # Model Architecture\n",
        "\n",
        "# model = tf.keras.Sequential([\n",
        "#     Conv2D(64, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
        "#     MaxPooling2D((2, 2)),\n",
        "#     Conv2D(128, (3, 3), activation='relu'),\n",
        "#     MaxPooling2D((2, 2)),\n",
        "#     Flatten(),\n",
        "#     Dense(256, activation='relu'),\n",
        "#     Dropout(0.5),\n",
        "#     Dense(num_classes, activation='softmax'),\n",
        "# ])\n",
        "\n",
        "# # Hyperparameter Tuning\n",
        "\n",
        "# optimizer = Adam(learning_rate=0.001)\n",
        "\n",
        "# #Loss Function and Metrics\n",
        "\n",
        "# model.compile(optimizer='adam', loss=categorical_crossentropy, metrics='accuracy')\n",
        "\n",
        "# # Define an EarlyStopping callback if needed.\n",
        "# early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "# history = model.fit(\n",
        "#     train_generator,\n",
        "#     steps_per_epoch=len(train_generator),\n",
        "#     epochs=12,\n",
        "#     validation_data=validation_generator,\n",
        "#     validation_steps=len(validation_generator),\n",
        "#     callbacks=[early_stopping],\n",
        "#     )\n",
        "\n",
        "# # Evaluate your model on a test dataset.\n",
        "\n",
        "# test_generator = test_datagen.flow_from_directory(\n",
        "#     test_path,\n",
        "#     target_size=(32, 32),\n",
        "#     batch_size=20,\n",
        "#     class_mode='categorical',\n",
        "# )\n",
        "\n",
        "# test_loss, test_accuracy = model.evaluate(test_generator, steps=len(test_generator))\n",
        "# print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}\")\n",
        "\n",
        "# # Save the trained model weights\n",
        "# model.save_weights('vgg_face_weights.h5')\n"
      ],
      "metadata": {
        "id": "Nsy0ZDKJTjyV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout"
      ],
      "metadata": {
        "id": "m3retmjGkpjY"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model(input_shape, num_classes):\n",
        "    model = tf.keras.Sequential([\n",
        "        Conv2D(64, (3, 3), activation='relu', input_shape=input_shape),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        Conv2D(128, (3, 3), activation='relu'),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        Flatten(),\n",
        "        Dense(256, activation='relu'),\n",
        "        Dropout(0.5),\n",
        "        Dense(num_classes, activation='softmax'),\n",
        "    ])\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "Joe_ZuVxjyeo"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lJ91KXz-0plT"
      },
      "outputs": [],
      "source": [
        "# import os\n",
        "# import numpy as np\n",
        "# import tensorflow as tf\n",
        "# from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "# from tensorflow.keras.optimizers import SGD\n",
        "\n",
        "# # Set the path to your dataset\n",
        "# dataset_dir = 'data'\n",
        "# train_path = '/content/drive/MyDrive/voting_final_project/images/archive/Training/Training'\n",
        "# test_path = '/content/drive/MyDrive/voting_final_project/images/archive/Testing/Testing'\n",
        "\n",
        "# # Define batch size and number of epochs for training\n",
        "# batch_size = 20\n",
        "# epochs = 14\n",
        "\n",
        "# # Create data generators for training and validation\n",
        "# train_datagen = ImageDataGenerator(\n",
        "#     rescale=1.0 / 255,\n",
        "#     rotation_range=20,\n",
        "#     width_shift_range=0.2,\n",
        "#     height_shift_range=0.2,\n",
        "#     horizontal_flip=True,\n",
        "#     validation_split=0.2  # Split data into training and validation sets\n",
        "# )\n",
        "\n",
        "# train_generator = train_datagen.flow_from_directory(\n",
        "#     train_path,\n",
        "#     target_size=(32, 32),\n",
        "#     batch_size=batch_size,\n",
        "#     class_mode='categorical',\n",
        "#     subset='training'  # Use the training subset\n",
        "# )\n",
        "\n",
        "# validation_generator = train_datagen.flow_from_directory(\n",
        "#     test_path,\n",
        "#     target_size=(32, 32),\n",
        "#     batch_size=batch_size,\n",
        "#     class_mode='categorical',\n",
        "#     subset='validation'  # Use the validation subset\n",
        "# )\n",
        "\n",
        "# # Define the input shape and number of classes\n",
        "# input_shape = (32, 32, 3)\n",
        "# num_classes = 6\n",
        "\n",
        "# # Create the model\n",
        "# model = create_model(input_shape, num_classes)\n",
        "\n",
        "# # Compile the model\n",
        "# optimizer = 'adam'\n",
        "# model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# # Train the model\n",
        "# model.fit(\n",
        "#     train_generator,\n",
        "#     steps_per_epoch=train_generator.samples // batch_size,\n",
        "#     validation_data=validation_generator,\n",
        "#     validation_steps=validation_generator.samples // batch_size,\n",
        "#     epochs=epochs\n",
        "# )\n",
        "\n",
        "# # Save the trained model weights\n",
        "# model.save_weights('vgg_face_weights.h5')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "\n",
        "# Set the path to your dataset\n",
        "train_path = '/content/drive/MyDrive/voting_final_project/images/archive/Training/Training'\n",
        "test_path = '/content/drive/MyDrive/voting_final_project/images/archive/Testing/Testing'\n",
        "\n",
        "# Define batch size and number of epochs for training\n",
        "batch_size = 32\n",
        "epochs = 100\n",
        "\n",
        "# Create data generators for training and validation with additional data augmentation\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1.0 / 255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    validation_split=0.2\n",
        ")\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_path,\n",
        "    target_size=(224, 224),  # Increase the target size for better performance\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "    test_path,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='validation'\n",
        ")\n",
        "\n",
        "# Define the input shape and number of classes\n",
        "input_shape = (224, 224, 3)\n",
        "num_classes = 6\n",
        "\n",
        "# Create the model with a deeper architecture\n",
        "model = tf.keras.Sequential([\n",
        "    Conv2D(64, (3, 3), activation='relu', input_shape=input_shape),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(256, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Flatten(),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "# Use the Adam optimizer with a lower learning rate for better convergence\n",
        "optimizer = Adam(learning_rate=0.0001)\n",
        "\n",
        "# Compile the model with categorical cross-entropy loss and accuracy metric\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model with an increased number of epochs\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=len(train_generator),\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=len(validation_generator),\n",
        "    epochs=epochs,\n",
        "    verbose=1  # Increase verbosity to monitor training progress\n",
        ")\n",
        "\n",
        "# Save the trained model weights\n",
        "model.save_weights('improved_vgg_face_weights.h5')\n",
        "\n",
        "# Evaluate the model on the test data\n",
        "test_loss, test_accuracy = model.evaluate(validation_generator, steps=len(validation_generator))\n",
        "print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5oahBA463hET",
        "outputId": "af6d0e75-e3ef-4dd7-e7bf-4c0297ed1570"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 22739 images belonging to 6 classes.\n",
            "Found 1558 images belonging to 6 classes.\n",
            "Epoch 1/100\n",
            "577/711 [=======================>......] - ETA: 24:25 - loss: 1.7611 - accuracy: 0.2542"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "NMcU4Vwqk2gO"
      },
      "outputs": [],
      "source": [
        "def crop_face(filename, required_size=(150, 150)):\n",
        "    img = cv2.imread(filename)\n",
        "    detector = MTCNN()\n",
        "    results = detector.detect_faces(img)\n",
        "    x, y, width, height = results[0]['box']\n",
        "    face = img[y:y+height, x:x+width]\n",
        "    image = Image.fromarray(face)\n",
        "    image = image.resize(required_size)\n",
        "    face_array = np.asarray(image)\n",
        "    return face_array, face"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zjOaVpK1AGnl"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade keras_vggface"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "krX_rm7s6_7o"
      },
      "outputs": [],
      "source": [
        "!pip install keras-applications\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "smrGmYLEnX_z"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "import cv2\n",
        "\n",
        "from mtcnn import MTCNN\n",
        "from keras_vggface.utils import preprocess_input\n",
        "from keras_vggface.utils import decode_predictions\n",
        "\n",
        "# from model import get_model\n",
        "\n",
        "model = get_model()\n",
        "print(model.summary())\n",
        "# Accessing model weights\n",
        "weights = model.get_weights()\n",
        "\n",
        "# Printing the weights of each layer\n",
        "for layer in model.layers:\n",
        "    print(f\"Layer: {layer.name}\")\n",
        "    layer_weights = layer.get_weights()\n",
        "    if layer_weights:\n",
        "        print(f\"Weights: {layer_weights[0]}\")\n",
        "        print(f\"Biases: {layer_weights[1]}\")\n",
        "    else:\n",
        "        print(\"No weights for this layer\")\n",
        "\n",
        "\n",
        "def crop_face(filename, required_size=(150, 150)):\n",
        "    img = cv2.imread(filename)\n",
        "    detector = MTCNN()\n",
        "    results = detector.detect_faces(img)\n",
        "    x, y, width, height = results[0]['box']\n",
        "    face = img[y:y+height, x:x+width]\n",
        "    image = Image.fromarray(face)\n",
        "    image = image.resize(required_size)\n",
        "    face_array = np.asarray(image)\n",
        "    return face_array, face\n",
        "\n",
        "def who_is_this(img, vgg_face_descriptor):\n",
        "    face_array, face = crop_face(img)\n",
        "    face_array = face_array.astype('float32')\n",
        "    input_sample = np.expand_dims(face_array, axis=0)\n",
        "    img_prediction = vgg_face_descriptor.predict(preprocess_input(input_sample))\n",
        "    results = decode_predictions(img_prediction)\n",
        "    prediction = results[0][0][0].replace(\"b'\", \"\").replace(\"'\",\"\")\n",
        "\n",
        "    return prediction\n",
        "\n",
        "def get_prediction(image_path):\n",
        "    model.load_weights(os.path.join(os.getcwd(), \"weight\", \"vgg_face_weights.h5\"))\n",
        "    vgg_face_descriptor = Model(inputs=model.layers[0].input,\\\n",
        "                                outputs=model.layers[-2].output)\n",
        "\n",
        "    return who_is_this(image_path, vgg_face_descriptor)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(get_prediction('test/Amir-Khan.jpg'))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "18wzL6HPy5Jz2ANfn6YPvnwITr3NYfiu7",
      "authorship_tag": "ABX9TyMxrRbApfCN6pCsnxxGt6Y+",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}